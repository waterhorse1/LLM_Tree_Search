{
    "summary": "This code defines functions to extract answers and ground truth values, creates a class \"Gsm8kEnv\" inheriting from \"CoTEnv\", and includes three methods for environment initialization and reward calculation.",
    "details": [
        {
            "comment": "This code defines functions for extracting answers and ground truth values from a string, as well as judging the correctness of an answer. The extract_answer function uses regex to find and strip the answer from a given completion string, handling invalid cases with INVALID_ANS. The extract_groundtruth function parses a groundtruth string and raises a ValueError if it cannot be converted to a float. The judge_correct function compares the extracted ground truth value to the provided answer, returning a warning if the extracted ground truth string cannot be converted to a float.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/gsm8k/env.py\":0-36",
            "content": "import copy\nimport re\nfrom typing import List, Optional\nimport numpy as np\nfrom tsllm.envs.base_env import CoTEnv, NoLegalActionException, INVALID_ANS\nfrom .prompt import COT_EXAMPLES, COT_TASK_DESC, PROBLEM_FORMAT_STR, SEP\nANS_RE = re.compile(r\"The answer is (\\-?[0-9\\.\\,]+)\")\nSTOP_STR = \"The answer is \"\ndef extract_answer(completion):\n    match = ANS_RE.search(completion)\n    if match:\n        match_str = match.group(1).strip()\n        match_str = match_str.replace(\",\", \"\")\n    else:\n        return INVALID_ANS\n    return match_str\ndef extract_groundtruth(groundtruth_str: str):\n    x = groundtruth_str.split(\"#### \")[1].strip().replace(\",\", \"\")\n    try:\n        float(x)\n    except:\n        raise ValueError(\n            \"Warning: Error should raise since the extracted groundtruth string {}\\\n             cannot be converted to float\".format(\n                x\n            )\n        )\n    return x\ndef judge_correct(problem_str: str, extracted_groundtruth: Optional[str], answer: str):\n    float_groundtruth = float(extracted_groundtruth)"
        },
        {
            "comment": "The code is defining a class called \"Gsm8kEnv\" which inherits from the \"CoTEnv\" class. It takes in various parameters such as config, math_problems, llm_gen_fn, tokenizer, etc. The class has a method \"_is_correct\" that checks if the provided completion is correct by comparing it with the expected answer using judge_correct function. The code also has exception handling to handle any exceptions during execution.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/gsm8k/env.py\":37-78",
            "content": "    try:\n        return abs(float(answer) - float_groundtruth) < 1e-5\n    except Exception:\n        return False\nclass Gsm8kEnv(CoTEnv):\n    sep = SEP\n    def __init__(\n        self,\n        config,\n        math_problems,\n        llm_gen_fn,\n        tokenizer,\n        task_desc_str: str = COT_TASK_DESC,\n        cot_example_str: str = COT_EXAMPLES,\n        problem_format_str: str = PROBLEM_FORMAT_STR,\n        reset=True,\n    ):\n        super().__init__(\n            config,\n            math_problems,\n            llm_gen_fn,\n            tokenizer,\n            task_desc_str,\n            cot_example_str,\n            problem_format_str,\n            reset,\n        )\n    @property\n    def stop_str(self):\n        return STOP_STR\n    def _is_correct(self, completion):\n        extracted_answer = extract_answer(completion)\n        # print(\"Compare: {} -- {}\".format(extrated_answer,\n        #  self.math_problem['answer']))\n        # return extrated_answer == self.math_problem['answer']\n        return judge_correct(\n            self.math_problem[\"question\"], self.math_problem[\"answer\"], extracted_answer"
        },
        {
            "comment": "This code defines three methods: \"init_action_history\", \"get_reward\", and an unnamed function that appears to be an environment initialization block. The \"init_action_history\" method adds the first prompted questions to the environment, while \"get_reward\" is a placeholder for implementing a learned reward model. The code returns 0 as a default reward until the reward model is implemented.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/gsm8k/env.py\":79-89",
            "content": "        )\n    def init_action_history(self):\n        # add the first prompted questions\n        return ([self.task_prefix] if self.task_prefix is not None else []) + [\n            f\"Question: {self.math_problem['question']}\\nAnswer: Let's think step by step\"\n        ]\n    def get_reward(self):\n        \"\"\"To implement based on learned reward model\"\"\"\n        return 0"
        }
    ]
}