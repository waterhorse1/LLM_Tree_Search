{
    "summary": "The script is running a test on the prontoqa environment using an offline reinforcement learning model. It uses multiple GPUs and specifies various environment test configurations, such as no terminal, with terminal, greedy, and soft target updates. The script also sets the number of processes per node to 8 and runs it with torchrun for distributed computing. The code calls the \"test_sft_and_v\" Python script from the \"tsllm/offline_rl\" directory. It specifies the critic model path, tokenizer path, CT2 directory, save directory for policy tests, and environment name. The test is not a few-shot learning scenario.",
    "details": [
        {
            "comment": "The script is running a test on the prontoqa environment using an offline reinforcement learning model. It uses multiple GPUs and specifies various environment test configurations, such as no terminal, with terminal, greedy, and soft target updates. The script also sets the number of processes per node to 8 and runs it with torchrun for distributed computing. The code calls the \"test_sft_and_v\" Python script from the \"tsllm/offline_rl\" directory. It specifies the critic model path, tokenizer path, CT2 directory, save directory for policy tests, and environment name. The test is not a few-shot learning scenario.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/train_mcts_scripts/prontoqa/test_policy_and_value.sh\":0-17",
            "content": "set -e\nexport TEST_NO_TERMINAL=1\n# export TEST_WITH_TERMINAL=1\n# export TEST_COT_GREEDY=1\n# export TEST_COT_SC=1\n# export CUDA_VISIBLE_DEVICES=0,1,2,3,4,5,6,7\nCT2_DIR={your ct2 model cache}\nCRITIC_PATH={your critic model cache}\ntorchrun --nproc_per_node=8 --master-port 29503 ../../tsllm/offline_rl/test_sft_and_v.py \\\n    --critic_model_path $CRITIC_PATH \\\n    --tokenizer_path $CRITIC_PATH \\\n    --ct2_dir $CT2_DIR \\\n    --save_dir $1/policy_ep1 \\\n    --env_name prontoqa \\\n    --test True \\\n    --is_few_shot False"
        }
    ]
}