{
    "summary": "The code initializes a Game24Env environment, tests answers, and prints the state of the environment. It also loads data from a JSONL file, tokenizes it, and displays lengths of critic_data, query string, and answer.",
    "details": [
        {
            "comment": "This code is initializing a Game24Env environment and testing different answers to see if they are correct. It also prints the state of the environment and uses build_query_str function for zero shot and few shot contextual understanding tasks.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/tests/test_game24.py\":0-37",
            "content": "from tsllm.envs.game24.env import (\n    Game24Env,\n    COT_EXAMPLES,\n    COT_TASK_DESC,\n    PROBLEM_FORMAT_STR,\n    SEP,\n)\nimport pytest\nif __name__ == \"__main__\":\n    problem_input = \"1 3 3 4\"\n    env = Game24Env(\n        config={},\n        math_problems=[{\"question\": \"1 3 3 4\", \"answer\": \"\"}],\n        tokenizer=None,\n        llm_gen_fn=None,\n        reset=False,\n    )\n    env.reset(False)\n    print(env.get_state())\n    print(env._is_correct(\"The answer is (3 * 4) * (3 - 1) = 24\"))\n    print(env._is_correct(\"\\n\\nThe answer is (3 * 4) * (3 - 1) = 24\"))\n    print(env._is_correct(\"The answer is (3 * 3) * (3 - 1) = 24\"))\n    print(env._is_correct(\"The answer is (3 * 4) * (3 - 1) = 23\"))\n    print(\"\\n\\n====== ZERO SHOT COT ============\")\n    build_query_str = Game24Env.build_query_str\n    print(\n        build_query_str(\n            COT_TASK_DESC, COT_EXAMPLES, PROBLEM_FORMAT_STR, problem_input, SEP, False\n        )\n    )\n    print(\"\\n\\n====== FEW SHOT COT ============\")\n    print(\n        build_query_str(\n            COT_TASK_DESC, COT_EXAMPLES, PROBLEM_FORMAT_STR, problem_input, SEP, True"
        },
        {
            "comment": "The code imports necessary libraries, defines a tokenizer, prepares a default small few-shot task dataset, and prints the lengths and samples of both the training data and the default critic dataset for \"game24\".",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/tests/test_game24.py\":38-67",
            "content": "        )\n    )\n    from transformers import AutoTokenizer\n    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Llama-2-7b-hf\")\n    print(\"\\n\\n====== default sft dataset ============\")\n    from tsllm.envs import get_default_sft_data_builder, get_env_datasets\n    train_ds, _  = get_env_datasets(\"game24\")\n    q2idx_dict = {}\n    for idx, problem_inst in enumerate(train_ds):\n        question = problem_inst[\"question\"]\n        q2idx_dict[question] = idx\n    sft_data = get_default_sft_data_builder(\n        \"game24\")(\n        \"tsllm/envs/game24/train_data/train_dedup.jsonl\",\n        q2idx_dict,\n        tokenizer=tokenizer,\n        add_eos_token=True,\n        is_few_shot=False,\n    )\n    print(\"Len train_ds: {}\\ntrian_ds[0]:\\n{}\".format(len(train_ds), train_ds[0]))\n    print(\"Len sft_data: {}\\nsft_data[0]:\\n{}\".format(len(sft_data), sft_data[0]))\n    print(\"\\n\\n====== default critic dataset ============\")\n    from tsllm.envs import get_default_critic_data_builder\n    critic_data = get_default_critic_data_builder(\"game24\")("
        },
        {
            "comment": "This code is loading data from a JSONL file, using a provided dictionary and tokenizer. It then prints the length of the critic_data, and the encoded lengths of the query string and answer in that data.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/tests/test_game24.py\":68-75",
            "content": "        \"tsllm/envs/game24/train_data/train_dedup.jsonl\",\n        q2idx_dict,\n        tokenizer=tokenizer,\n        is_few_shot=False\n    )\n    print(\"Len critic_data: {}\\ncritic_data[0]:\\n{}\".format(len(critic_data), critic_data[0]))\n    print(len(tokenizer.encode(critic_data[0][\"query_str\"]+critic_data[0][\"answer\"])))\n    print(len(tokenizer.encode(critic_data[0][\"query_str\"])))"
        }
    ]
}