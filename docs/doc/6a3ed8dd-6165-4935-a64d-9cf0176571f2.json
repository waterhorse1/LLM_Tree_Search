{
    "summary": "The code generates train and test datasets, customizes for specific models, encodes answer tokens, and builds query strings for unique answers, removing duplicates. It also creates a list of dictionaries containing query string, answer, value index, and reward list using relevant functions/classes.",
    "details": [
        {
            "comment": "This code defines two functions: `get_train_test_dataset` and `build_dataset`. The former builds train and test datasets using the latter function. The latter function builds a dataset for training, which loads data from `load_dataset`, and requires customization for training models on specific datasets. It returns a dataloader for the dataset.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/rlhf/data.py\":0-29",
            "content": "from transformers import AutoTokenizer\nfrom datasets import load_dataset, load_from_disk\nimport json\nimport numpy as np\nfrom tsllm.distributed.utils import print_with_rank\nfrom tsllm.offline_rl.utils import load_jsonl\nfrom .prompt import PROBLEM_FORMAT_STR, SEP\nfrom .env import RLHF_TokenEnv\n'''\ndef get_train_test_dataset(*args, **kwargs):\n    train_dataset = build_dataset(dataset_name = \"imdb\", setting = \"train\", **kwargs)\n    test_dataset = build_dataset(dataset_name = \"imdb\", setting = \"test\", **kwargs)\n    return train_dataset, test_dataset\ndef build_dataset(model_name, dataset_name=\"imdb\", setting=\"train\", input_text_length=5):\n    \"\"\"\n    Build dataset for training. This builds the dataset from `load_dataset`, one should\n    customize this function to train the model on its own dataset.\n    Args:\n        dataset_name (`str`):\n            The name of the dataset to be loaded.\n    Returns:\n        dataloader (`torch.utils.data.DataLoader`):\n            The dataloader for the dataset.\n    \"\"\"\n    tokenizer = AutoTokenizer.from_pretrained(model_name)"
        },
        {
            "comment": "Code chunk loads and processes a dataset for training and testing. It pads tokens, tokenizes samples, sets data format to torch, and defines function to get train/test datasets based on the number of samples required.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/rlhf/data.py\":30-57",
            "content": "    tokenizer.pad_token = tokenizer.eos_token\n    # load imdb with datasets\n    ds = load_dataset(dataset_name, split=setting)\n    ds = ds.rename_columns({\"text\": \"review\"})\n    #ds = ds.filter(lambda x: len(x[\"review\"]) > 200, batched=False)\n    #input_size = LengthSampler(input_min_text_length, input_max_text_length)\n    def tokenize(sample):\n        input_ids = tokenizer.encode(sample[\"review\"])[: input_text_length]\n        sample[\"question\"] = tokenizer.decode(input_ids)\n        return sample\n    ds = ds.map(tokenize, batched=False)\n    ds.set_format(type=\"torch\")\n    return ds\n'''\ndef get_train_test_dataset(*args, **kwargs):\n    if \"num_train_data\" in kwargs.keys():\n        num_train_data = kwargs.pop(\"num_train_data\")\n        if \"path\" in kwargs.keys():\n            train_dataset = load_dataset(**kwargs, split=f\"train[:{num_train_data}]\")\n            test_dataset = load_dataset(**kwargs, split=f\"train[{num_train_data}:]\")\n        else:\n            full_dataset = load_from_disk(**kwargs)[\"train\"]\n            train_dataset = full_dataset.select([i for i in range(num_train_data)])"
        },
        {
            "comment": "The code defines a function that takes in various parameters such as `train_data_pre`, `train_data_post`, and `full_dataset`. If the `test_dataset` is not specified, it creates both train and test datasets by selecting specific ranges of data from the full dataset. It then renames the \"prompt\" column to \"question\" for both datasets. The code also defines an inner function called `get_value_index()` that takes in a question and answer and calculates the value index based on token length. This function may be used later in the code.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/rlhf/data.py\":58-82",
            "content": "            test_dataset = full_dataset.select(\n                [i for i in range(num_train_data, len(full_dataset))]\n            )\n    else:\n        train_data_pre = kwargs.pop(\"train_data_pre\")\n        train_data_post = kwargs.pop(\"train_data_post\")\n        full_dataset = load_from_disk(**kwargs)[\"train\"]\n        train_dataset = full_dataset.select(\n            [i for i in range(train_data_pre, train_data_post)]\n        )\n        test_dataset = full_dataset.select(\n            [i for i in range(train_data_pre, train_data_post)]\n        )\n    train_dataset = train_dataset.rename_column(\"prompt\", \"question\")\n    test_dataset = test_dataset.rename_column(\"prompt\", \"question\")\n    return train_dataset, test_dataset\ndef build_offline_data_component(path, q2idx_dict, tokenizer, sep):\n    def get_value_index(question, answer):\n        pre_state_token_length = len(tokenizer.encode(question + sep))\n        index = [pre_state_token_length]\n        if not sep == \"\":\n            answer_list = answer.split(sep)\n            for action in answer_list:"
        },
        {
            "comment": "Code calculates the action length for each token, appends it to index list. If action length is 0, prints potential issues. Else, encodes answer tokens and appends 1 to index list for each token. Calculates cumulative sum of index list and subtracts 1. Loads jsonl data and creates traj_dict_list by iterating over predata, considering unique questions and their corresponding answers.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/rlhf/data.py\":83-109",
            "content": "                action_length = len(\n                    tokenizer.encode(action + sep, add_special_tokens=False)\n                )\n                index.append(action_length)\n                if action_length == 0:\n                    print_with_rank(\n                        \"possbile problems met in online value instance building. {}\".format(\n                            action\n                        )\n                    )\n        else:\n            answer_tokens = tokenizer.encode(answer, add_special_tokens=False)\n            for token in answer_tokens:\n                index.append(1)\n        index = np.cumsum(index) - 1\n        return index\n    predata = load_jsonl(path)\n    traj_dict_list = []\n    for idx, d in enumerate(predata):\n        question = d[\"question\"]\n        if question in q2idx_dict.keys():\n            task_idx = q2idx_dict[question]\n            full_answer_list = d[\"answer\"]\n            # deduplication\n            # note that in Dahoas/synthetic-instruct-gptj-pairwise, these exists several questions that are the same"
        },
        {
            "comment": "This code ensures that duplicate answer texts are removed from the full_answer_list, creating a unique list of answers. Then, for each unique answer in the updated list, it builds a query string using the RLHF_TokenEnv class. The function get_value_index is used to find the value index, and np.zeros creates a reward list with all values set to 0 except the last one which gets the \"reward\" value from the unique answer dictionary. Lastly, a traj_dict is created with an 'idx' key for task index.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/rlhf/data.py\":110-131",
            "content": "            # but here the deduplication only happens for the answer list given one question\n            # So it is still possible to have sample example when add traj\n            unique_answer_list = list(\n                {item[\"text\"]: item for item in full_answer_list}.values()\n            )\n            answer_list = []\n            for a in unique_answer_list:\n                answer = a[\"text\"]\n                query_str = RLHF_TokenEnv.build_query_str(\n                    cot_task_desc=None,\n                    cot_examples=None,\n                    problem_format_str=PROBLEM_FORMAT_STR,\n                    problem_input=question,\n                    sep=SEP,\n                    is_few_shot=False,\n                )\n                value_index = get_value_index(query_str, answer)\n                # :-1 is value index, -1 is the reward index\n                reward_list = np.zeros(len(value_index) - 1)\n                reward_list[-1] = a[\"reward\"]\n                traj_dict = {\n                    \"idx\": task_idx,"
        },
        {
            "comment": "This function takes in a problem input and returns a list of dictionaries, where each dictionary contains the generated query string, answer, value index, and reward list. The build_query_str function formats the problem input using the PROBLEM_FORMAT_STR prompt from the prompt module.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/rlhf/data.py\":132-145",
            "content": "                    \"query_str\": query_str,\n                    \"answer\": answer,\n                    \"value_index\": value_index,\n                    \"reward_list\": reward_list,\n                }\n                traj_dict_list.append(traj_dict)\n                answer_list.append(answer)\n    return traj_dict_list\n# def build_query_str(problem_input, config=None):\n#     from .prompt import PROBLEM_FORMAT_STR\n#     return PROBLEM_FORMAT_STR.format(problem_input)"
        }
    ]
}