{
    "summary": "The code provides a configurable RLConfig class with options for reinforcement learning tasks, including model, optimizer, scheduler, tokenizer, train settings, MCTS configuration, environment settings, and optional FSDP configuration. It also includes methods to convert dictionary to RLConfig object and serialize it back into dictionary.",
    "details": [
        {
            "comment": "This code defines two classes, `BaseConfig` and `ModelConfig`, using the `dataclass` decorator for creating Python data classes. The `from_dict` class method allows objects of these classes to be instantiated from dictionaries. The `__getitem__` and `get` methods provide dictionary-like access to config attributes. The `ModelConfig` also includes optional fields for model path, critic model path, cache dir, model arch type, peft configuration, and value state dict path.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/config.py\":0-36",
            "content": "from typing import Dict, List, Optional, Any\nfrom dataclasses import dataclass, field\nfrom torch.distributed.fsdp import ShardingStrategy\nfrom torch.distributed.fsdp.fully_sharded_data_parallel import StateDictType\nfrom peft import PeftConfig\n@dataclass\nclass BaseConfig:\n    @classmethod\n    def from_dict(cls, config: Dict[str, Any]):\n        return cls(**config)\n    def __getitem__(self, k):\n        if hasattr(self, k):\n            return getattr(self, k)\n        else:\n            raise KeyError(\"Have no attribute named {}.\".format(k))\n    def get(self, k, default):\n        if hasattr(self, k):\n            return getattr(self, k)\n        else:\n            return default\n@dataclass\nclass ModelConfig(BaseConfig):\n    model_path: str\n    critic_model_path: Optional[str] = None\n    cache_dir: Optional[str] = None\n    model_arch_type: str = \"causal\"\n    peft_config: Optional[Dict] = None\n    value_state_dict_path: Optional[Dict] = None\n    # config for critic model, \n    #  since we have \"ValueHeadLLM\" and \"AutoModelForCausalLMWithValueHead\""
        },
        {
            "comment": "This code defines several classes and configuration settings for a machine learning model. It includes options for the value model type, tokenizer path, training epochs, sequence length, and more. These settings allow users to customize their model's behavior and parameters during training and inference.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/config.py\":37-77",
            "content": "    #  this may be removed in future versions.\n    value_model_type_name: str=\"ValueHeadLLM\"\n    def __post_init__(self):\n        from peft import get_peft_config\n        if isinstance(self.peft_config, dict):\n            self.peft_config = get_peft_config(self.peft_config)\n@dataclass\nclass TokenizerConfig(BaseConfig):\n    tokenizer_path: str\n    padding_side: str = \"left\"\n    truncation_side: str = \"right\"\n@dataclass\nclass TrainConfig(BaseConfig):\n    seq_length: int\n    epochs: int\n    micro_batch_size: Optional[int] = 4\n    sft_micro_batch_size: Optional[int] = 4\n    gradient_accumulation_steps: Optional[int] = 4\n    n_rollout: int = 10\n    n_problem_per_gpu_rollout: Optional[int] = 100\n    n_step_per_rollout: Optional[int] = 20\n    eval_interval: Optional[int] = 1\n    eval_n_problem: Optional[int] = 1\n    checkpoint_interval: int = 1\n    gamma: float = 0.99\n    gae_lambda: float = 0.95\n    pure_sft: bool = False\n    sft_loss_coef: Optional[float] = 1.0\n    value_loss_coef: Optional[float] = 0.5\n    train_epoch: Optional[int] = 1"
        },
        {
            "comment": "This code defines a class \"MCTSConfig\" which contains various configuration options for the MCTS_train project. It includes options like project name, entity and group names, checkpoint directory, optimizer saving, logging directories, tracker usage, seed value, minibatch size, and task-specific dataset kwargs. These settings can be used to customize the behavior of the MCTS_train project according to specific needs.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/config.py\":79-111",
            "content": "    project_name: str = \"MCTS_train\"\n    entity_name: Optional[str] = None\n    group_name: Optional[str] = None\n    checkpoint_dir: Optional[str] = \"ckpts\"\n    save_optimizer: bool = True\n    rollout_logging_dir: Optional[str] = None\n    tracker: Optional[str] = \"wandb\"\n    logging_dir: Optional[str] = None\n    tags: Optional[List[str]] = field(default_factory=list)\n    seed: int = 42\n    minibatch_size: Optional[int] = None\n    pre_sft_datapath: Optional[str] = None\n    pre_onpolicy_datapath: Optional[str] = None\n    pre_onpolicy_datapath_train_test: Optional[str] = None\n    pre_onpolicy_datapath_test: Optional[str] = None\n    onpolicy_per_problem_max_size: Optional[int] = 3\n    sft_per_problem_max_size: Optional[int] = 5\n    env_name: str = \"\"\n    task_dataset_kwargs: dict = field(default_factory=dict)\n    # task_dataset_kwargs is a dict that should store task-specific\n    # kwargs for task_module.get_train_test_dataset\n    # e.g. num_train_data: Optional[int] = 1000 is for envs.gsm8k\n@dataclass\nclass MCTSConfig(BaseConfig):"
        },
        {
            "comment": "This code defines several config classes for different model components such as OptimizerConfig, SchedulerConfig, EnvConfig, and FSDPConfig. Each class has attributes that control various aspects of the model's behavior and training process. The classes inherit from BaseConfig and use dataclasses for easy configuration handling. Some optional parameters are specified with \"Optional\" types to allow flexibility in their usage.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/config.py\":112-151",
            "content": "    num_simulations: int = 20\n    pb_c_base: float = 19652\n    pb_c_init: float = 10\n    root_dirichlet_alpha: float = 0.3\n    root_noise_weight: float = 0.25\n@dataclass\nclass OptimizerConfig(BaseConfig):\n    name: str\n    kwargs: Dict[str, Any] = field(default_factory=dict)\n@dataclass\nclass SchedulerConfig(BaseConfig):\n    name: str\n    kwargs: Dict[str, Any] = field(default_factory=dict)\n    warmup_ratio: Optional[float] = None\n    num_warmup_steps: Optional[int] = None\n# CAUTION: keep an eye on extra comma\n@dataclass\nclass EnvConfig(BaseConfig):\n    stop_str: str = \"The answer is \"\n    max_actions: int = 2\n    max_length: int = 6\n    is_few_shot: bool = False\n    generation_config: dict = field(default_factory=dict)\n@dataclass\nclass FSDPConfig(BaseConfig):\n    mixed_precision: bool = True\n    use_fp16: bool = False\n    sharding_strategy: ShardingStrategy = ShardingStrategy.FULL_SHARD\n    checkpoint_type: StateDictType = StateDictType.SHARDED_STATE_DICT\n    # alternatively can use SHARDED_STATE_DICT save one file per rank, and can resize the world-size."
        },
        {
            "comment": "This code defines a class `RLConfig` with various configuration options for reinforcement learning tasks, including model, optimizer, scheduler, tokenizer, train settings, MCTS configuration, and environment settings. It also includes an optional FSDP configuration if present in the input dictionary. The class has two methods: `from_dict` to convert a dictionary into an `RLConfig` object, and `to_dict` to serialize the config back into a dictionary.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/config.py\":152-184",
            "content": "    fsdp_activation_checkpointing: bool = True\n    pure_bf16: bool = True\n    optimizer: str = \"AdamW\"\n@dataclass\nclass RLConfig:\n    model: ModelConfig\n    optimizer: OptimizerConfig\n    scheduler: SchedulerConfig\n    tokenizer: TokenizerConfig\n    train: TrainConfig\n    mcts: MCTSConfig\n    env: EnvConfig\n    fsdp: Optional[FSDPConfig] = None\n    @classmethod\n    def from_dict(cls, config: Dict):\n        \"\"\"\n        Convert dictionary to TRLConfig.\n        \"\"\"\n        return cls(\n            model=ModelConfig.from_dict(config[\"model\"]),\n            tokenizer=TokenizerConfig.from_dict(config[\"tokenizer\"]),\n            optimizer=OptimizerConfig.from_dict(config[\"optimizer\"]),\n            scheduler=SchedulerConfig.from_dict(config[\"scheduler\"]),\n            train=TrainConfig.from_dict(config[\"train\"]),\n            mcts=MCTSConfig.from_dict(config[\"mcts\"]),\n            env=EnvConfig.from_dict(config[\"env\"]),\n            fsdp=FSDPConfig.from_dict(config[\"fsdp\"]) if \"fsdp\" in config else None,\n        )\n    def to_dict(self):"
        },
        {
            "comment": "This function creates a dictionary 'data' containing the attributes of model, tokenizer, optimizer, scheduler, train, mcts, and environment objects. If fsdp is not None, it also includes 'fsdp'. It then returns this data dictionary.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/config.py\":185-197",
            "content": "        data = {\n            \"model\": self.model.__dict__,\n            \"tokenizer\": self.tokenizer.__dict__,\n            \"optimizer\": self.optimizer.__dict__,\n            \"scheduler\": self.scheduler.__dict__,\n            \"train\": self.train.__dict__,\n            \"mcts\": self.mcts.__dict__,\n            \"env\": self.env.__dict__,\n        }\n        if self.fsdp is not None:\n            data[\"fsdp\"] = self.fsdp.__dict__\n        return data"
        }
    ]
}