{
    "summary": "The code creates a function to import environment modules, define tasks with datasets or data builders, and construct query/response strings for judging correct answers.",
    "details": [
        {
            "comment": "The code defines three functions: `get_env_datasets`, `get_default_sft_data_builder`, and `get_default_critic_data_builder`. These functions are used to import a specific environment module (`env_name`) and return the training and testing datasets, or default data builders for sequence-to-sequence tasks and critic tasks. The functions use `importlib` to import the specified environment module and `functools.partial` to create partial function applications with the necessary arguments for building data components.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/__init__.py\":0-27",
            "content": "from importlib import import_module\nfrom functools import partial\nfrom transformers import PreTrainedTokenizer\nfrom typing import Optional, Callable, Dict\nfrom .utils import build_critic_data_component, build_sft_data_component\ndef get_env_datasets(env_name: str, **kwargs):\n    task_module = import_module(f\"tsllm.envs.{env_name}\")\n    return task_module.get_train_test_dataset(**kwargs)\ndef get_default_sft_data_builder(env_name: str, **kwargs):\n    task_module = import_module(f\"tsllm.envs.{env_name}\")\n    return partial(\n        build_sft_data_component,\n        build_query_str_fn=task_module.Env.build_query_str,\n        build_response_str_fn=task_module.Env.build_response_str,\n        sep=task_module.SEP,\n        cot_task_desc_str=task_module.COT_TASK_DESC,\n        cot_example_str=task_module.COT_EXAMPLES,\n        problem_format_str=task_module.PROBLEM_FORMAT_STR,\n    )\ndef get_default_critic_data_builder(env_name: str, **kwargs):\n    task_module = import_module(f\"tsllm.envs.{env_name}\")\n    return partial("
        },
        {
            "comment": "The function `get_default_query_str_builder` takes an environment name (env_name) and optional keyword arguments, imports the corresponding task module, and returns a function that builds a query string based on provided parameters. The returned function uses methods from the imported task module to construct the query string. Similarly, `get_default_response_str_builder` does something similar but for building response strings.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/__init__.py\":28-57",
            "content": "        build_critic_data_component,\n        build_query_str_fn=task_module.Env.build_query_str,\n        sep=task_module.SEP,\n        cot_task_desc_str=task_module.COT_TASK_DESC,\n        cot_example_str=task_module.COT_EXAMPLES,\n        problem_format_str=task_module.PROBLEM_FORMAT_STR,\n    )\ndef get_default_query_str_builder(env_name: str, **kwargs):\n    task_module = import_module(f\"tsllm.envs.{env_name}\")\n    def fn(problem_input: str, is_few_shot: bool):\n        return task_module.Env.build_query_str(\n            cot_task_desc=task_module.COT_TASK_DESC,\n            cot_examples=task_module.COT_EXAMPLES,\n            problem_format_str=task_module.PROBLEM_FORMAT_STR,\n            problem_input=problem_input,\n            sep=task_module.SEP,\n            is_few_shot=is_few_shot,\n        )\n    return fn\ndef get_default_response_str_builder(env_name: str, **kwargs):\n    task_module = import_module(f\"tsllm.envs.{env_name}\")\n    def fn(problem_input: str, tokenizer: PreTrainedTokenizer, add_eos_token: bool):\n        return task_module.Env.build_response_str("
        },
        {
            "comment": "This code defines a function \"get_env_answer_checker\" that takes an environment name as input and returns a judging function for the given task. The function imports the relevant module, and then creates another function \"judge_answer\" which takes problem statement, groundtruth, and answer completion as inputs and calls relevant methods from the imported module to judge if the answer is correct or not.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/__init__.py\":58-76",
            "content": "            problem_input,\n            tokenizer,\n            add_eos_token,\n        )\n    return fn\ndef get_env_answer_checker(env_name):\n    task_module = import_module(f\"tsllm.envs.{env_name}\")\n    def judge_answer(problem_str, groundtruth_str, answer_completion: str):\n        # should feed the unprocessed `groundtruth_str` and `answer_completion_str`\n        return task_module.judge_correct(\n            problem_str,\n            task_module.extract_groundtruth(groundtruth_str),\n            task_module.extract_answer(answer_completion),\n        )\n    return judge_answer"
        }
    ]
}