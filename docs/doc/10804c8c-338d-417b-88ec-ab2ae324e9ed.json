{
    "summary": "The code imports necessary modules and functions, sets up an environment for a contextual understanding task, fine-tunes pretrained models, and prints critical data details.",
    "details": [
        {
            "comment": "The code imports necessary classes and functions from related modules, creates an RLHF_TokenEnv environment with a single problem input, resets the environment, prints its state, and then builds a query string for a zero-shot contextual understanding task using provided descriptions, examples, and problem input.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/tests/test_rlhf.py\":0-28",
            "content": "from tsllm.envs.rlhf.env import RLHF_TokenEnv, PROBLEM_FORMAT_STR, SEP\nfrom tsllm.envs.rlhf.prompt import COT_EXAMPLES, COT_TASK_DESC\nimport pytest\nif __name__ == \"__main__\":\n    problem_input = \"1 3 3 4\"\n    env = RLHF_TokenEnv(\n        config={},\n        problems=[{\"question\": \"1 3 3 4\", \"answer\": \"\"}],\n        tokenizer=None,\n        llm_forward_fn=None,\n        reward_fn=None,\n        reset=False,\n    )\n    env.reset(False)\n    print(env.get_state())\n    # print(env._is_correct(\"The answer is (3 * 4) * (3 - 1) = 24\"))\n    # print(env._is_correct(\"\\n\\nThe answer is (3 * 4) * (3 - 1) = 24\"))\n    # print(env._is_correct(\"The answer is (3 * 3) * (3 - 1) = 24\"))\n    # print(env._is_correct(\"The answer is (3 * 4) * (3 - 1) = 23\"))\n    build_query_str = RLHF_TokenEnv.build_query_str\n    print(\"\\n\\n====== ZERO SHOT COT ============\")\n    print(\n        build_query_str(\n            COT_TASK_DESC, COT_EXAMPLES, PROBLEM_FORMAT_STR, problem_input, SEP, False\n        )\n    )\n    # print(\"\\n\\n====== FEW SHOT COT ============\")"
        },
        {
            "comment": "This code imports necessary libraries and builds the default supervised fine-tuning (sft) dataset using a pretrained tokenizer. It then prints details about the sft_data and train_ds, including their lengths and examples.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/tests/test_rlhf.py\":29-55",
            "content": "    # print(\n    #     build_query_str(\n    #         COT_TASK_DESC, COT_EXAMPLES, PROBLEM_FORMAT_STR, problem_input, True\n    #     )\n    # )\n    from transformers import AutoTokenizer\n    tokenizer = AutoTokenizer.from_pretrained(\"vicgalle/gpt2-open-instruct-v1\")\n    print(\"\\n\\n====== default sft dataset ============\")\n    from tsllm.envs import get_default_sft_data_builder, get_env_datasets\n    train_ds, _  = get_env_datasets(\"game24\")\n    q2idx_dict = {}\n    for idx, problem_inst in enumerate(train_ds):\n        question = problem_inst[\"question\"]\n        q2idx_dict[question] = idx\n    sft_data = get_default_sft_data_builder(\n        \"rlhf\")(\n        \"tsllm/envs/game24/train_data/train_dedup.jsonl\",\n        q2idx_dict,\n        tokenizer=tokenizer,\n        add_eos_token=True,\n        is_few_shot=False,\n    )\n    print(\"Len train_ds: {}\\ntrian_ds[0]:\\n{}\".format(len(train_ds), train_ds[0]))\n    print(\"Len sft_data: {}\\nsft_data[0]:\\n{}\".format(len(sft_data), sft_data[0]))\n    print(\"\\n\\n====== default critic dataset ============\")"
        },
        {
            "comment": "The code imports the `get_default_critic_data_builder` function from `tsllm.envs` module and uses it to create a `critic_data` object with given parameters: \"rlhf\" mode, path to train data file, query to index dictionary (q2idx_dict), tokenizer, and non-few shot setting. It then prints the length of critic_data, first sample in critic_data, encoded length of the concatenation of query string and answer in critic_data, and lastly the encoded length of just the query string from critic_data.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/tests/test_rlhf.py\":56-65",
            "content": "    from tsllm.envs import get_default_critic_data_builder\n    critic_data = get_default_critic_data_builder(\"rlhf\")(\n        \"tsllm/envs/game24/train_data/train_dedup.jsonl\",\n        q2idx_dict,\n        tokenizer=tokenizer,\n        is_few_shot=False\n    )\n    print(\"Len critic_data: {}\\ncritic_data[0]:\\n{}\".format(len(critic_data), critic_data[0]))\n    print(len(tokenizer.encode(critic_data[0][\"query_str\"]+critic_data[0][\"answer\"])))\n    print(len(tokenizer.encode(critic_data[0][\"query_str\"])))"
        }
    ]
}