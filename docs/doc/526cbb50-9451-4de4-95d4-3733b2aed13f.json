{
    "summary": "This code initializes a critic model based on the provided value_model_type_name and model path, loading the state dictionary for the critic model and handling different types of models.",
    "details": [
        {
            "comment": "This function loads a critic model. It takes the path to the critic model and state dict, device information, and value model type name as parameters. If the value model type is \"ValueHeadLLM\", it creates an instance of ValueHeadedLLM from the pretrained model at the critic model path, then moves it to the specified device with bfloat16 datatype. If a state dict file exists, it loads that too.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/model/__init__.py\":0-24",
            "content": "import os\nfrom typing import Optional, Union\nimport torch\nfrom tsllm.distributed.utils import print_with_rank\nfrom tsllm.model.modeling_prm import ValueHeadedLLM\nfrom tsllm.model.modeling_actor_critic import AutoModelForCausalLMWithValueHead\ndef load_critic_model(\n    critic_model_path: str,\n    state_dict_path: Optional[str],\n    device,\n    value_model_type_name: str = \"ValueHeadLLM\",\n) -> Union[ValueHeadedLLM, AutoModelForCausalLMWithValueHead]:\n    ############ LOAD V MODEL ###################\n    if value_model_type_name == \"ValueHeadLLM\":\n        critic = ValueHeadedLLM.from_pretrained(critic_model_path).to(\n            device=device, dtype=torch.bfloat16\n        )\n        # for some checkpoints stored by deepspeed with optimizer state\n        #  need to load the state dict manually.\n        if state_dict_path is not None:\n            print_with_rank(\"Loading state dict from {}\".format(state_dict_path))\n            state_dict = torch.load(\n                os.path.join(state_dict_path, \"pytorch_model/mp_rank_00_model_states.pt\"),"
        },
        {
            "comment": "This code initializes a critic model based on the provided value_model_type_name and model path. It loads the state dictionary for the critic model, handles different types of models, and returns the initialized critic model.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/model/__init__.py\":25-48",
            "content": "                map_location=\"cpu\",\n            )\n            critic.base_model.load_state_dict(state_dict[\"module\"], strict=False)\n            critic.cat_head.load_state_dict(\n                {\n                    k.replace(\"cat_head.\", \"\"): v\n                    for k, v in state_dict[\"module\"].items()\n                    if k.startswith(\"cat_head.\")\n                }\n            )\n    elif value_model_type_name == \"AutoModelForCausalLMWithValueHead\":\n        critic = AutoModelForCausalLMWithValueHead.from_pretrained(\n            critic_model_path\n        ).to(device=device, dtype=torch.bfloat16)\n        if state_dict is not None:\n            raise NotImplementedError\n    else:\n        raise ValueError(\n            \"Unknown value model type name {}.\".format(value_model_type_name)\n        )\n    return critic"
        }
    ]
}