{
    "summary": "The `build_critic_data_component` function constructs a data component for tasks, utilizes tokenization and generates query and response strings from JSONL files. It returns a list of dictionaries containing information like index, query, answer, response string, handles optional parameters and initializes reward_list with zeros. It assigns rewards to the correct answers and appends it to traj_dict_list before returning it.",
    "details": [
        {
            "comment": "This function builds a data component for the task, taking in various parameters like JSONL path, dictionary mapping questions to indices, tokenizer, boolean values for adding EOS tokens, whether it's few-shot learning or not, and functions for building query and response strings. It loads the JSONL file, filters out irrelevant questions, constructs queries based on optional task descriptions and examples, and populates a list of (question index, full answer) tuples to be used in the training dataset.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/utils.py\":0-32",
            "content": "from typing import Dict, Optional, Union, Callable\nimport numpy as np\nfrom tsllm.distributed.utils import print_with_rank\nfrom tsllm.offline_rl.utils import load_jsonl\nfrom transformers import PreTrainedTokenizer\nfrom pathlib import Path\nfrom torch.utils.data import Dataset\nimport jsonlines\ndef build_sft_data_component(\n    jsonl_path: Union[Path, str],\n    q2idx_dict: Dict,\n    tokenizer: PreTrainedTokenizer,\n    add_eos_token: bool,\n    is_few_shot: bool,\n    build_query_str_fn: Callable,\n    build_response_str_fn: Callable,\n    sep: str,\n    cot_task_desc_str: Optional[str] = None,\n    cot_example_str: Optional[str] = None,\n    problem_format_str: Optional[str] = None,\n):\n    predata = load_jsonl(jsonl_path)\n    q_r_dict_list = []\n    for idx, d in enumerate(predata):\n        question = d[\"question\"]\n        if question not in q2idx_dict:\n            continue\n        task_idx = q2idx_dict[question]\n        full_answer_list = d[\"answer\"]\n        query_str = build_query_str_fn(\n            cot_task_desc=cot_task_desc_str,"
        },
        {
            "comment": "This code defines a function `build_critic_data_component` that takes in various parameters and returns a list of dictionaries (`q_r_dict_list`). The function seems to build data components for a task, where it uses tokenization, builds response strings, and creates dictionaries with information such as index, query string, answer, and response string. It also takes optional parameters like `cot_task_desc_str`, `cot_example_str`, and `problem_format_str`. The function utilizes other helper functions like `build_response_str_fn` and `get_value_index`.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/utils.py\":33-65",
            "content": "            cot_examples=cot_example_str,\n            problem_format_str=problem_format_str,\n            problem_input=question,\n            sep=sep,\n            is_few_shot=is_few_shot,\n        )\n        for answer_output in full_answer_list:\n            answer_txt = answer_output[\"text\"]\n            response_str = build_response_str_fn(answer_txt, tokenizer, add_eos_token)\n            traj_dict = {\n                \"idx\": task_idx,\n                \"query_str\": query_str,\n                \"answer\": answer_txt,\n                \"response_str\": response_str,\n            }\n            q_r_dict_list.append(traj_dict)\n    return q_r_dict_list\ndef build_critic_data_component(\n    jsonl_path: Union[Path, str],\n    q2idx_dict: Dict,\n    tokenizer: PreTrainedTokenizer,\n    sep: str,\n    is_few_shot: bool,\n    build_query_str_fn: Callable,\n    cot_task_desc_str: Optional[str] = None,\n    cot_example_str: Optional[str] = None,\n    problem_format_str: Optional[str] = None,\n):\n    def get_value_index(q_str: str, answer_str: str):"
        },
        {
            "comment": "The code calculates the tokenized length of the question string and adds it to a list called 'indices'. If there is a separator in the answer string, the answer string is split into a list of actions. For each action, the code appends the action and separator to the current string, updates the check_indices list with the tokenized length minus 1, and prints a warning if the action is empty. After looping through all actions, the check_indices are converted to a numpy array and becomes the new 'indices'. If there's no separator in the answer string, the code encodes the answer string into tokens and appends 1 to the indices list for each token. The indices list is then cumulatively summed and subtracted by 1 to create the final 'indices'.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/utils.py\":66-93",
            "content": "        pre_state_token_length = len(tokenizer.encode(q_str))\n        indices = [pre_state_token_length]\n        if sep != \"\":\n            answer_list = answer_str.split(sep)\n            check_indices = [pre_state_token_length - 1]\n            current_str = q_str\n            for action in answer_list:\n                current_str += action + sep\n                if len(action) == 0:\n                    print_with_rank(\n                        \"WARNING: possbile problems met in sft instance building. {}\".format(\n                            action\n                        )\n                    )\n                    continue\n                check_indices.append(len(tokenizer.encode(current_str)) - 1)\n            check_indices = np.array(check_indices)\n            indices = check_indices\n        else:\n            answer_tokens = tokenizer.encode(answer_str, add_special_tokens=False)\n            for token in answer_tokens:\n                indices.append(1)\n            indices = np.cumsum(indices) - 1\n        return indices"
        },
        {
            "comment": "This code reads a list of preloaded JSONL data and iterates through it, filtering out questions not in q2idx_dict. For each question, it builds a query string using provided arguments and then iterates through the answers for that question. If there is no \"reward\" key in the answer dict, it uses the \"correct\" key instead. It retrieves the value index of the answer from the query string and adds a tuple (task_idx, value_index, -1) to traj_dict_list if sep is empty.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/utils.py\":95-120",
            "content": "    predata = load_jsonl(jsonl_path)\n    traj_dict_list = []\n    for idx, d in enumerate(predata):\n        question = d[\"question\"]\n        if question not in q2idx_dict.keys():\n            continue\n        task_idx = q2idx_dict[question]\n        full_answer_list = d[\"answer\"]\n        query_str = build_query_str_fn(\n            cot_task_desc=cot_task_desc_str,\n            cot_examples=cot_example_str,\n            problem_format_str=problem_format_str,\n            problem_input=question,\n            sep=sep,\n            is_few_shot=is_few_shot,\n        )\n        for answer_output in full_answer_list:\n            \"\"\"answer_output is a dict with keys:\n            \"text\", \"reward\",\n            if there is not \"reward\" key, use \"correct\" key\n            \"\"\"\n            if len(sep) > 1:\n                print_with_rank(\"WARNING: sep is not empty, but {}\".format(sep))\n            answer = answer_output[\"text\"].strip(sep)\n            value_index = get_value_index(query_str, answer)\n            # :-1 is value index, -1 is the reward index"
        },
        {
            "comment": "This code initializes a reward_list with zeros, assigns rewards to the answer output based on correctness, adds reward_list to traj_dict and appends it to traj_dict_list. The function returns traj_dict_list.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/envs/utils.py\":121-134",
            "content": "            reward_list = np.zeros(len(value_index) - 1)\n            if \"reward\" not in answer_output:\n                answer_output[\"reward\"] = 1.0 if answer_output[\"correct\"] else -1.0\n            reward_list[-1] = answer_output[\"reward\"]\n            traj_dict = {\n                \"idx\": task_idx,\n                \"query_str\": query_str,\n                \"answer\": answer + sep,\n                \"value_index\": value_index,\n                \"reward_list\": reward_list,\n            }\n            traj_dict_list.append(traj_dict)\n    return traj_dict_list"
        }
    ]
}