{
    "summary": "The code includes a `collate_fn` function and TrajBuffer class for managing trajectory instances, along with the MultiTrajBuffer class to handle multiple buffers for different tasks. The code uses a dataloader to iterate over data and prepares it for model training or evaluation by loading, batching, shuffling, clearing history, and retrieving elements.",
    "details": [
        {
            "comment": "This code defines a function called \"collate_fn\" that takes in a padding token ID, an ignore index, and a sequence of TrajInstance objects. It then pads the input IDs, labels, attn_mask, and returns using the provided padding values and returns a TrajBatch object containing the padded data.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/data/traj_buffer.py\":0-38",
            "content": "from typing import List, Sequence, Dict\nimport torch\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom functools import partial\nfrom torch.nn.utils.rnn import pad_sequence\nfrom tsllm.distributed.utils import print_rank_0, print_with_rank\nfrom tsllm.rl.data.node_types_new import TrajBatch, TrajInstance\nimport bisect\nimport json\nimport os\ndef collate_fn(\n    pad_token_id: int,\n    IGNORE_INDEX: int,\n    elems: Sequence[TrajInstance],\n) -> TrajBatch:\n    input_ids = pad_sequence(\n        [elem.input_ids for elem in elems],\n        padding_value=pad_token_id,\n        batch_first=True,\n    )\n    label = pad_sequence(\n        [elem.label for elem in elems],\n        padding_value=IGNORE_INDEX,\n        batch_first=True,\n    )\n    attn_mask = input_ids.ne(pad_token_id)\n    # result = torch.cat([elem.result for elem in elems])\n    returns = pad_sequence(\n        [elem.returns for elem in elems],\n        padding_value=0.0,\n        batch_first=True,\n    )\n    mask = pad_sequence(\n        [elem.mask for elem in elems],"
        },
        {
            "comment": "This code defines a class `TrajBuffer` for managing a buffer of trajectory instances. It keeps a list of these instances in `self.history`, has a maximum size (`self.max_size`), and ignores specific values (`IGNORE_INDEX`). The `push` method appends new instances, while the `add` method checks for duplicates before adding new instances or removing old ones if the buffer is full.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/data/traj_buffer.py\":39-73",
            "content": "        padding_value=0,\n        batch_first=True,\n    )\n    return TrajBatch(input_ids, label, attn_mask, returns, mask)\nclass TrajBuffer(Dataset):\n    def __init__(self, max_size, pad_token_id, IGNORE_INDEX=-100) -> None:\n        super().__init__()\n        self.history: List[TrajInstance] = []\n        self.max_size = max_size\n        self.IGNORE_INDEX = IGNORE_INDEX\n        self.pad_token_id = pad_token_id\n    def push(self, exps: Sequence[TrajInstance]):\n        self.history += exps\n    def add(self, inst: TrajInstance):\n        # add example\n        # check whether the traj is the same with history\n        # check whether the buffer is full\n        result = \"\"\n        for d in self.history:\n            # need double check\n            if inst.response == d.response:\n                result = \"repeat\"\n                break\n        if not result == \"repeat\":\n            if len(self.history) == self.max_size:\n                self.history.pop(0)\n                result = \"full\"\n            self.history.append(inst)\n        return result"
        },
        {
            "comment": "This code defines a class for a dataset buffer containing multiple trajectory data. It has methods to clear, get item length, retrieve items, save the data, and create a DataLoader object for efficient batch processing during training. The dataset is represented by instances of the MultiTrajBuffer class.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/data/traj_buffer.py\":75-112",
            "content": "    def clear(self):\n        self.history = []\n    def __len__(self):\n        return len(self.history)\n    def __getitem__(self, index):\n        return self.history[index]\n    def save(self, path):\n        # save the databuffer\n        data_dict_list = [\n            {\"question\": data.question, \"response\": data.response}\n            for data in self.history\n        ]\n        directory = os.path.dirname(path)\n        if not os.path.exists(directory):\n            os.makedirs(directory)\n        with open(path, \"w\") as file:\n            for entry in data_dict_list:\n                json_str = json.dumps(entry)\n                file.write(json_str + \"\\n\")\n    def create_loader(self, batch_size: int, shuffle: bool) -> DataLoader:\n        return DataLoader(\n            self,\n            batch_size,\n            shuffle=shuffle,\n            collate_fn=partial(collate_fn, self.pad_token_id, self.IGNORE_INDEX),\n        )\nclass MultiTrajBuffer(Dataset):\n    def __init__(\n        self,\n        num,\n        per_problem_max_size,\n        pad_token_id,"
        },
        {
            "comment": "This class represents a collection of `TrajBuffer` instances, each having the same configuration and serving a specific task. The `add` method adds an instance to one of these buffers, and if the buffer is full or contains a repeated example, it prints a message. The `save` method saves all buffer instances as separate JSONL files, and the `clear_idx` and `clear_all` methods clear the specified buffer or all buffers respectively.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/data/traj_buffer.py\":113-147",
            "content": "        IGNORE_INDEX=-100,\n        buffer_name=\"SFT\",\n    ) -> None:\n        super().__init__()\n        self.num = num\n        self.buffer_name = buffer_name\n        self.IGNORE_INDEX = IGNORE_INDEX\n        self.pad_token_id = pad_token_id\n        self.history: Dict[TrajBuffer] = {\n            i: TrajBuffer(per_problem_max_size, pad_token_id, IGNORE_INDEX)\n            for i in range(num)\n        }\n    def add(self, idx: int, inst: TrajInstance):\n        result = self.history[idx].add(inst)\n        if result == \"full\":\n            print_with_rank(f\"The {idx} buffer is full, pop out the first traj\")\n        elif result == \"repeat\":\n            print_with_rank(f\"The {idx} buffer has the same example\")\n        else:\n            pass\n    def save(self, path):\n        import os\n        for i in range(self.num):\n            self.history[i].save(\n                os.path.join(path, f\"Buffer_{self.buffer_name}_{i}.jsonl\")\n            )\n    def clear_idx(self, idx: int):\n        self.history[idx].clear()\n    def clear_all(self):"
        },
        {
            "comment": "This code defines a custom data structure, likely for storing trajectory-like data. It has methods to clear its internal history, calculate cumulative sizes of the stored sequences, and retrieve elements at specific indices. It also provides a DataLoader to create an iterable loader for training or testing.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/data/traj_buffer.py\":148-182",
            "content": "        for i in range(self.num):\n            self.history[i].clear()\n    def cumsum(self, sequence):\n        r, s = [], 0\n        for e in range(self.num):\n            l = len(sequence[e])\n            r.append(l + s)\n            s += l\n        return r\n    def __len__(self):\n        return self.cumulative_sizes[-1]\n    @property\n    def cumulative_sizes(self):\n        return self.cumsum(self.history)\n    def __getitem__(self, idx):\n        if idx < 0:\n            if -idx > len(self):\n                raise ValueError(\n                    \"absolute value of index should not exceed dataset length\"\n                )\n            idx = len(self) + idx\n        dataset_idx = bisect.bisect_right(self.cumulative_sizes, idx)\n        if dataset_idx == 0:\n            sample_idx = idx\n        else:\n            sample_idx = idx - self.cumulative_sizes[dataset_idx - 1]\n        return self.history[dataset_idx][sample_idx]\n    def create_loader(self, batch_size: int, shuffle: bool) -> DataLoader:\n        return DataLoader(\n            self,"
        },
        {
            "comment": "This code initializes a MultiTrajBuffer object with specified parameters, adds positive and negative samples to it, modifies the input_ids of the first sample, and then creates a DataLoader object for accessing the buffer in batches.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/data/traj_buffer.py\":183-215",
            "content": "            batch_size,\n            shuffle=shuffle,\n            collate_fn=partial(collate_fn, self.pad_token_id, self.IGNORE_INDEX),\n        )\nif __name__ == \"__main__\":\n    # test\n    multi_buffer = MultiTrajBuffer(num=2, per_problem_max_size=3, pad_token_id=0)\n    sample = TrajInstance(\n        torch.ones(2),\n        torch.ones(3),\n        torch.tensor([1]),\n        torch.ones(3),\n        torch.ones(3),\n        \"hello\",\n    )\n    negative_sample = TrajInstance(\n        -torch.ones(3),\n        -torch.ones(3),\n        torch.tensor([0]),\n        -torch.ones(3),\n        -torch.ones(3),\n        \"hello\",\n    )\n    multi_buffer.add(idx=0, inst=sample)\n    multi_buffer.add(idx=0, inst=negative_sample)\n    multi_buffer.add(idx=1, inst=sample)\n    multi_buffer.add(idx=1, inst=negative_sample)\n    print(multi_buffer.history[0].history, multi_buffer.history[1].history)\n    multi_buffer.history[0].history[0].input_ids = torch.zeros(3)\n    # print(multi_buffer[0], multi_buffer[1])\n    dataloader = multi_buffer.create_loader(2, False)"
        },
        {
            "comment": "The code iterates over data from a dataloader and prints each data batch. This likely prepares data for model training or evaluation. The dataloader might be responsible for loading, batching, and shuffling the data.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/tsllm/rl/data/traj_buffer.py\":216-217",
            "content": "    for data in dataloader:\n        print(data)"
        }
    ]
}