{
    "summary": "The code reads JSONL files, performs deduplication and calculates average tokens, merges two input files based on questions, counts new instances added, stores merged data in an output file while printing the total count of instances, subsamples objects based on condition, counts answers, checks answer length, prints progress, and outputs the result to an output file or JSONLines in a Jupyter notebook setting compatible with Python 3.10.12 using IPython3 lexer and nbformat version 4.",
    "details": [
        {
            "comment": "This code block is importing necessary libraries and defining functions for deduplication. It reads data from a JSONL file, checks the correctness using a specified checker function, and removes duplicates while counting total tokens. The deduplicated objects are stored in a list, and the number of items before and after deduplication is also tracked.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/train_mcts_scripts/gsm8k/it1_gsm8k.ipynb\":0-46",
            "content": "{\n \"cells\": [\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 1,\n   \"metadata\": {},\n   \"outputs\": [],\n   \"source\": [\n    \"import jsonlines\\n\",\n    \"import json\\n\",\n    \"from tsllm.envs import get_env_answer_checker\\n\",\n    \"import numpy as np\\n\",\n    \"import random\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Deduplication\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 26,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"5199.825371336812\\n\",\n      \"89676 -> 78732 after deduplicate.\\n\",\n      \"correct: 0.732091144642585\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"input_file_path = \\\"train_mcts_scripts/gsm8k/iteration1/mcts_rollout-k12.jsonl\\\"\\n\",\n    \"output_file_path = \\\"train_mcts_scripts/gsm8k/iteration1/mcts_rollout-k12-dedup.jsonl\\\"\\n\",\n    \"\\n\",\n    \"check_fn = get_env_answer_checker(\\\"gsm8k\\\")\\n\",\n    \"\\n\",\n    \"total_tokens = 0\\n\",\n    \"cnt = 0\\n\",\n    \"dedup_objs = []\\n\",\n    \"cnt_before_dedup, cnt_after_dedup = 0, 0\\n\","
        },
        {
            "comment": "This code reads input data, iterates over objects within the data, checks for duplicate text values and removes them using deduplication. It counts total tokens, counts the number of times a correct answer is found, and finally prints the average tokens per object and the count of objects before/after deduplication.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/train_mcts_scripts/gsm8k/it1_gsm8k.ipynb\":47-69",
            "content": "    \"correct_cnt = 0\\n\",\n    \"with jsonlines.open(input_file_path, \\\"r\\\") as reader:\\n\",\n    \"    for obj in reader:\\n\",\n    \"        total_tokens += obj[\\\"result\\\"][\\\"#token\\\"]\\n\",\n    \"        cnt += 1\\n\",\n    \"        texts = set()\\n\",\n    \"        new_output_list = []\\n\",\n    \"        for o in obj[\\\"output\\\"]:\\n\",\n    \"            cnt_before_dedup += 1\\n\",\n    \"            txt = o[\\\"text\\\"]\\n\",\n    \"            if txt not in texts:\\n\",\n    \"                cnt_after_dedup += 1\\n\",\n    \"                o[\\\"correct\\\"] = check_fn(obj[\\\"question\\\"], obj[\\\"groundtruth\\\"], txt)\\n\",\n    \"                if o[\\\"correct\\\"]:\\n\",\n    \"                    correct_cnt += 1\\n\",\n    \"                new_output_list.append(o)\\n\",\n    \"                texts.add(txt)\\n\",\n    \"        obj.pop(\\\"output\\\")\\n\",\n    \"        obj[\\\"answer\\\"] = new_output_list\\n\",\n    \"        dedup_objs.append(obj)\\n\",\n    \"\\n\",\n    \"print(total_tokens / cnt)\\n\",\n    \"print(\\\"{} -> {} after deduplicate.\\\".format(cnt_before_dedup, cnt_after_dedup))\\n\","
        },
        {
            "comment": "This code reads two input files (previous and current rollout data) and merges them before storing the merged data in an output file. It also calculates and prints the number of new instances added during the merge process, as well as the total count of instances after the merge.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/train_mcts_scripts/gsm8k/it1_gsm8k.ipynb\":70-107",
            "content": "    \"print(\\\"correct: {}\\\".format(correct_cnt / cnt_after_dedup))\\n\",\n    \"\\n\",\n    \"\\n\",\n    \"with jsonlines.open(output_file_path, \\\"w\\\") as writer:\\n\",\n    \"    for obj in dedup_objs:\\n\",\n    \"        writer.write(obj)\\n\",\n    \"\\n\",\n    \"del input_file_path, output_file_path\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Merge previous rollout data and current rollout data for policy training\\n\",\n    \"\\n\",\n    \"set `input_file_path_0` to be the path of previous rollout data, `input_file_path_1` to be the path of current rollout_data\\n\",\n    \"\\n\",\n    \"set `output_file_path` to be where you store the merged data\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 3,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"ADD 6504 new instances\\n\",\n      \"TOTAL DATA: 64134\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"input_file_path_1 = \\\"train_mcts_scripts/gsm8k/iteration1/mcts_rollout-k12-dedup.jsonl\\\"\\n\",\n    \"input_file_path_0 = \\\"tslmm/envs/gsm8k/train_data/sft_init.jsonl\\\"\\n\","
        },
        {
            "comment": "This code reads two JSONL files and merges their content based on the question. It counts the number of new instances added and prints the count.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/train_mcts_scripts/gsm8k/it1_gsm8k.ipynb\":108-129",
            "content": "    \"output_file_path = \\\"train_mcts_scripts/gsm8k/iteration1/mcts_rollout-k12-merge_train-dedup.jsonl\\\"\\n\",\n    \"\\n\",\n    \"obj_dict = {}\\n\",\n    \"cnt = 0\\n\",\n    \"total_cnt = 0\\n\",\n    \"with jsonlines.open(input_file_path_1, \\\"r\\\") as reader:\\n\",\n    \"    for obj in reader:\\n\",\n    \"        obj_dict[obj[\\\"i\\\"]] = obj\\n\",\n    \"\\n\",\n    \"with jsonlines.open(input_file_path_0, \\\"r\\\") as reader:\\n\",\n    \"    for i, obj in enumerate(reader):\\n\",\n    \"        obj_to_merge = obj_dict[i]\\n\",\n    \"        assert obj_to_merge[\\\"question\\\"] == obj[\\\"question\\\"]\\n\",\n    \"        current_texts = set([o[\\\"text\\\"] for o in obj_to_merge[\\\"answer\\\"]])\\n\",\n    \"\\n\",\n    \"        come_in_output = obj[\\\"answer\\\"][0]\\n\",\n    \"        if come_in_output[\\\"text\\\"] not in current_texts:\\n\",\n    \"            obj_to_merge[\\\"answer\\\"].append(come_in_output)\\n\",\n    \"            cnt += 1\\n\",\n    \"        total_cnt += len([x for x in obj_to_merge[\\\"answer\\\"] if x[\\\"correct\\\"]])\\n\",\n    \"\\n\",\n    \"print(\\\"ADD {} new instances\\\".format(cnt))\\n\","
        },
        {
            "comment": "This code reads in two input files containing data, merges them, and outputs the merged result to an output file. The input files are paths of previous and current rollout data, and the output file is where the merged data is stored. It also prints a message indicating the total number of items in the dataset after the merge operation.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/train_mcts_scripts/gsm8k/it1_gsm8k.ipynb\":130-165",
            "content": "    \"print(\\\"TOTAL DATA: {}\\\".format(total_cnt))\\n\",\n    \"\\n\",\n    \"# SL sft training data\\n\",\n    \"with jsonlines.open(output_file_path, \\\"w\\\") as writer:\\n\",\n    \"    for obj in obj_dict.values():\\n\",\n    \"        writer.write(obj)\\n\",\n    \"\\n\",\n    \"del input_file_path, output_file_path\"\n   ]\n  },\n  {\n   \"cell_type\": \"markdown\",\n   \"metadata\": {},\n   \"source\": [\n    \"## Merge previous rollout data and current rollout data for critic training\\n\",\n    \"\\n\",\n    \"set `input_file_path_0` to be the path of previous rollout data, `input_file_path_1` to be the path of current rollout_data\\n\",\n    \"\\n\",\n    \"set `output_file_path` to be where you store the merged data\"\n   ]\n  },\n  {\n   \"cell_type\": \"code\",\n   \"execution_count\": 24,\n   \"metadata\": {},\n   \"outputs\": [\n    {\n     \"name\": \"stdout\",\n     \"output_type\": \"stream\",\n     \"text\": [\n      \"ADD 280037/345945 NEW DATA, NOW 358769\\n\"\n     ]\n    }\n   ],\n   \"source\": [\n    \"input_file_path_0 = \\\"tsllm/offline_rl/gsm8k_data/processed/gsm8k_train_cot_sample_sft_k100_merged_dedup_sample17x3.jsonl\\\"\\n\","
        },
        {
            "comment": "The code initializes variables, sets random seed for reproducibility, reads input and output file paths, creates an object dictionary from the input file, counts total answer count, subsample objects based on condition, checks if 'answer' length is greater than K, and prints progress.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/train_mcts_scripts/gsm8k/it1_gsm8k.ipynb\":166-190",
            "content": "    \"input_file_path_1 = \\\"train_mcts_scripts/gsm8k/iteration1/mcts_rollout-k12-dedup.jsonl\\\"\\n\",\n    \"output_file_path = \\\"train_mcts_scripts/gsm8k/iteration1/mcts_rollout-k12-value-sl_train-dedup.jsonl\\\"\\n\",\n    \"\\n\",\n    \"seed = 1\\n\",\n    \"random.seed(seed)\\n\",\n    \"np.random.seed(seed)\\n\",\n    \"\\n\",\n    \"obj_dict = {}\\n\",\n    \"with jsonlines.open(input_file_path_1, \\\"r\\\") as reader:\\n\",\n    \"    for obj in reader:\\n\",\n    \"        obj_dict[obj[\\\"i\\\"]] = obj\\n\",\n    \"        \\n\",\n    \"\\n\",\n    \"cnt = 0\\n\",\n    \"total_cnt = 0\\n\",\n    \"merged_dedup_cnt = 0\\n\",\n    \"K = 51 - 12\\n\",\n    \"subsample_obj_dict = {}\\n\",\n    \"with jsonlines.open(input_file_path_0, \\\"r\\\") as reader:\\n\",\n    \"    for i, obj in enumerate(reader):\\n\",\n    \"        assert obj[\\\"question\\\"] == obj_dict[i][\\\"question\\\"]\\n\",\n    \"        current_texts = set([o[\\\"text\\\"] for o in obj_dict[i][\\\"answer\\\"]])\\n\",\n    \"        total_cnt += len(obj[\\\"answer\\\"])        \\n\",\n    \"        print(len(obj[\\\"answer\\\"]), end=\\\"\\\\r\\\")\\n\",\n    \"        if len(obj[\\\"answer\\\"]) > K:\\n\","
        },
        {
            "comment": "This code is part of a Jupyter notebook and is responsible for processing data. It sub-samples objects from the input list, adds new text to a set and appends them to the answer list. The code then calculates the number of newly added data and prints this information. Finally, it writes the updated data to a JSONLines file.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/train_mcts_scripts/gsm8k/it1_gsm8k.ipynb\":191-222",
            "content": "    \"            subsample_list = np.random.choice(obj[\\\"answer\\\"], K, replace=False)\\n\",\n    \"        else:\\n\",\n    \"            subsample_list = obj[\\\"answer\\\"]\\n\",\n    \"\\n\",\n    \"        for o in subsample_list:\\n\",\n    \"            if o[\\\"text\\\"] not in current_texts:\\n\",\n    \"                current_texts.add(o[\\\"text\\\"])\\n\",\n    \"                obj_dict[i][\\\"answer\\\"].append(o)\\n\",\n    \"                cnt += 1\\n\",\n    \"        merged_dedup_cnt += len(obj_dict[i][\\\"answer\\\"])\\n\",\n    \"print(\\\"ADD {}/{} NEW DATA, NOW {}\\\".format(cnt, total_cnt, merged_dedup_cnt))\\n\",\n    \"\\n\",\n    \"# SL sft training data\\n\",\n    \"with jsonlines.open(output_file_path, \\\"w\\\") as writer:\\n\",\n    \"    for obj in obj_dict.values():\\n\",\n    \"        writer.write(obj)\"\n   ]\n  }\n ],\n \"metadata\": {\n  \"kernelspec\": {\n   \"display_name\": \"mcts\",\n   \"language\": \"python\",\n   \"name\": \"python3\"\n  },\n  \"language_info\": {\n   \"codemirror_mode\": {\n    \"name\": \"ipython\",\n    \"version\": 3\n   },\n   \"file_extension\": \".py\",\n   \"mimetype\": \"text/x-python\","
        },
        {
            "comment": "Code snippet defines the kernel version and settings for a Jupyter notebook, ensuring compatibility with Python 3.10.12 using IPython3 lexer and supports nbformat version 4.",
            "location": "\"/media/root/Toshiba XG3/works/LLM_Tree_Search/docs/src/train_mcts_scripts/gsm8k/it1_gsm8k.ipynb\":223-232",
            "content": "   \"name\": \"python\",\n   \"nbconvert_exporter\": \"python\",\n   \"pygments_lexer\": \"ipython3\",\n   \"version\": \"3.10.12\"\n  },\n  \"orig_nbformat\": 4\n },\n \"nbformat\": 4,\n \"nbformat_minor\": 2\n}"
        }
    ]
}